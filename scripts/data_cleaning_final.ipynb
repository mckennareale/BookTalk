{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iO8Zthcgzpkp"
      },
      "outputs": [],
      "source": [
        "# setup\n",
        "import pandas as pd\n",
        "import ast\n",
        "import string\n",
        "from google.colab import drive\n",
        "import re\n",
        "from datetime import datetime\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# ratings_raw = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/Raw_datasets/Books_rating.csv\")\n",
        "# ratings = ratings_raw[['Title', 'Id']].drop_duplicates(subset = 'Title', keep = 'first') # keep only 1 ID per title\n",
        "# ratings = ratings.dropna()\n",
        "# books = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/Raw_datasets/books_data.csv\")\n",
        "# enrichment = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/enrichments/amazonbooks_enrichment_withratings_50k.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FFRRNXmR0eMX"
      },
      "outputs": [],
      "source": [
        "# data cleaning\n",
        "bm = books.merge(ratings[['Title', 'Id']], on='Title', how='left') # add ID info\n",
        "bm['publishedDate'] = bm['publishedDate'].str[:4] # only take year\n",
        "bm['authors'].tolist()\n",
        "def safe_eval(val):\n",
        "    if pd.isna(val):\n",
        "        return []\n",
        "    return ast.literal_eval(val)\n",
        "bm['authors'] = bm['authors'].apply(safe_eval)\n",
        "bm['authors'] = bm['authors'].apply(lambda x: [author.strip('\"') for author in x])\n",
        "bm['authors'] = bm['authors'].apply(lambda x: None if isinstance(x, list) and len(x) == 0 else x)\n",
        "\n",
        "bm['categories'] = bm['categories'].apply(safe_eval)\n",
        "bm['categories'] = bm['categories'].apply(lambda x: [category.strip('\"') for category in x])\n",
        "bm['categories'] = bm['categories'].apply(lambda x: None if isinstance(x, list) and len(x) == 0 else x)\n",
        "bm['categories'] = bm['categories'].apply(lambda x: x.lower() if isinstance(x, str) else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MECzkz2cBHBo"
      },
      "outputs": [],
      "source": [
        "# mapping table of author to book ID (accounts for >1 author/book)\n",
        "authors_mapping = bm.explode('authors', ignore_index=True)\n",
        "cols = ['Title', 'Id', 'authors']\n",
        "authors_mapping = authors_mapping[cols]\n",
        "authors_mapping = authors_mapping.rename(columns={\"Title\": \"title\", \"Id\": \"id\"})\n",
        "authors_mapping = authors_mapping.dropna(subset=['title', 'id', 'authors'])\n",
        "authors_mapping = authors_mapping.drop_duplicates(keep=\"first\")\n",
        "#authors_mapping.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/for_database_upload/authors_mapping_modified.csv\", index=False, header = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7SA0V45NEWCQ"
      },
      "outputs": [],
      "source": [
        "bm = bm.drop(columns = 'authors')\n",
        "bm = bm.merge(enrichment, left_on='Title', right_on = 'name', how='left')\n",
        "\n",
        "# rename and reorder columns, save to CSV\n",
        "bm = bm.drop(columns = 'name')\n",
        "bm = bm.rename(columns={\"Title\": \"title\", \"Id\": \"id\"}, errors=\"raise\")\n",
        "bm = bm.rename(columns={\"previewLink\": \"preview_link\",\n",
        "                        \"publishedDate\": \"published_date\",\n",
        "                        \"infoLink\": \"info_link\",\n",
        "                        \"ratingsCount\": \"ratings_count\"}, errors=\"raise\")\n",
        "new_col_order = [\"id\", \"title\", \"description\", \"image\", \"preview_link\",\n",
        "                 \"publisher\", \"published_date\", \"info_link\", \"categories\",\n",
        "                 \"ratings_count\", \"city_set_in\", \"country_set_in\",\n",
        "                 \"period_set_in\", \"film_name\", \"classification\"]\n",
        "bm = bm[new_col_order]\n",
        "# drop rows with NULL values for id\n",
        "bm = bm.dropna(subset=['id'])\n",
        "bm = bm.where(pd.notnull(bm), None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_periods(value):\n",
        "    if isinstance(value, str):\n",
        "        # Handle \"various time periods\" (or similar unrecognized text)\n",
        "        if 'various time periods' in value.lower():\n",
        "            return None, None\n",
        "\n",
        "        # Handle \"Contemporary\" (let's assume contemporary is 2000 to current year)\n",
        "        if 'contemporary' in value.lower():\n",
        "            current_year = datetime.now().year\n",
        "            return 2000, current_year  # Assuming \"Contemporary\" means 2000-present\n",
        "\n",
        "        # Handle \"c. X BC - c. Y BC\" by processing the 'c.' and BCE years\n",
        "        if 'c.' in value.lower() and 'BC' in value.upper():\n",
        "            value = value.replace('c.', '').strip()  # Remove 'c.'\n",
        "            parts = re.split(r'\\s*-\\s*', value)\n",
        "            start, end = None, None\n",
        "\n",
        "            if len(parts) == 2:  # Ensure we have a range\n",
        "                # Handle the start date\n",
        "                start_match = re.search(r'(\\d+)\\s*BC', parts[0], re.IGNORECASE)\n",
        "                if start_match:\n",
        "                    start = -int(start_match.group(1))  # BCE years are negative\n",
        "\n",
        "                # Handle the end date\n",
        "                end_match = re.search(r'(\\d+)\\s*BC', parts[1], re.IGNORECASE)\n",
        "                if end_match:\n",
        "                    end = -int(end_match.group(1))  # BCE years are negative\n",
        "\n",
        "            return start, end\n",
        "\n",
        "        # Handle \"about X - Y\" by removing \"about\" and processing the numbers\n",
        "        if 'about' in value.lower():\n",
        "            value = value.lower().replace('about', '').strip()\n",
        "            parts = re.split(r'\\s*-\\s*', value)\n",
        "            if len(parts) == 2:\n",
        "                start = int(parts[0].replace(',', ''))  # Remove commas and convert to int\n",
        "                end = int(parts[1].replace(',', ''))    # Same for the second number\n",
        "                return start, end\n",
        "\n",
        "        # Handle '19th century'\n",
        "        elif re.search(r'\\d{1,2}(st|nd|rd|th) century', value, re.IGNORECASE):\n",
        "            match = re.search(r'(\\d{1,2})', value)\n",
        "            if match:\n",
        "                century = int(match.group(1))\n",
        "                start = (century - 1) * 100\n",
        "                end = start + 99\n",
        "                return start, end\n",
        "\n",
        "        # Handle a range like '1930-1940'\n",
        "        elif ' - ' in value:\n",
        "            parts = value.split(' - ')\n",
        "            if len(parts) == 2 and all(part.isdigit() for part in parts):\n",
        "                start = int(parts[0])\n",
        "                end = int(parts[1])\n",
        "                return min(start, end), max(start, end)  # Ensure we return a valid range\n",
        "\n",
        "        # Handle centuries like '19th century'\n",
        "        elif re.search(r'\\d{1,2}(st|nd|rd|th) century', value, re.IGNORECASE):\n",
        "            match = re.search(r'(\\d{1,2})', value)\n",
        "            if match:\n",
        "                century = int(match.group(1))\n",
        "                start = (century - 1) * 100\n",
        "                end = start + 99\n",
        "                return start, end\n",
        "\n",
        "        # Handle ranges with BCE/CE (e.g., 'c. 1200 BCE - 70 CE')\n",
        "        if re.search(r'BCE|CE', value, re.IGNORECASE):\n",
        "            value = value.replace(\"c.\", \"\").strip()  # Remove 'c.' if present\n",
        "            parts = re.split(r'\\s*-\\s*', value)\n",
        "            start, end = None, None\n",
        "\n",
        "            if len(parts) == 2:  # Ensure we have a range\n",
        "                # Handle the start date\n",
        "                start_match = re.search(r'(\\d+)\\s*(BCE|CE)', parts[0], re.IGNORECASE)\n",
        "                if start_match:\n",
        "                    start = int(start_match.group(1))\n",
        "                    if start_match.group(2).upper() == \"BCE\":\n",
        "                        start = -start  # BCE years are negative\n",
        "\n",
        "                # Handle the end date\n",
        "                end_match = re.search(r'(\\d+)\\s*(BCE|CE)', parts[1], re.IGNORECASE)\n",
        "                if end_match:\n",
        "                    end = int(end_match.group(1))\n",
        "                    if end_match.group(2).upper() == \"BCE\":\n",
        "                        end = -end  # BCE years are negative\n",
        "\n",
        "            return start, end\n",
        "\n",
        "        # Handle single years like '1899' or '1200 BCE'\n",
        "        elif re.search(r'\\d+\\s*(BCE|CE)', value, re.IGNORECASE):\n",
        "            match = re.search(r'(\\d+)\\s*(BCE|CE)', value, re.IGNORECASE)\n",
        "            year = int(match.group(1))\n",
        "            if match.group(2).upper() == \"BCE\":\n",
        "                year = -year  # BCE years are negative\n",
        "            return year, year\n",
        "\n",
        "        elif value.isdigit():  # Single numeric year\n",
        "            year = int(value)\n",
        "            return year, year\n",
        "\n",
        "        # If the value is unrecognized text, print it and return None\n",
        "        return None, None\n",
        "\n",
        "    # If the value is None or empty string, return None\n",
        "    return None, None\n",
        "\n",
        "bm[['time_period_start', 'time_period_end']] = bm['period_set_in'].apply(extract_periods).apply(pd.Series)"
      ],
      "metadata": {
        "id": "AmwgyLPO1kKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cities = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/for_database_upload/11-24_updated_cities.csv\")\n",
        "cities.loc[cities['country_name'] == 'Namibia', 'country_iso'] = 'NA' # fixing Namibia country ISO being NA\n",
        "cities = cities.dropna(subset = 'city')\n",
        "cities = cities.rename(columns={\"id\": \"setting_id\"})\n",
        "#cities.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/for_database_upload/new_cities_final.csv\", index=False)"
      ],
      "metadata": {
        "id": "nSGLuBhqwkIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dataprep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "mMmUEk2pb_lo",
        "outputId": "970932f4-0871-4745-ad6e-47dfe134f4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dataprep\n",
            "  Downloading dataprep-0.4.5-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.6 in /usr/local/lib/python3.10/dist-packages (from dataprep) (3.11.10)\n",
            "Collecting bokeh<3,>=2 (from dataprep)\n",
            "  Downloading bokeh-2.4.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: dask>=2022.3.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (2024.10.0)\n",
            "Collecting flask<3,>=2 (from dataprep)\n",
            "  Downloading flask-2.3.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting flask_cors<4.0.0,>=3.0.10 (from dataprep)\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: ipywidgets<8.0,>=7.5 in /usr/local/lib/python3.10/dist-packages (from dataprep) (7.7.1)\n",
            "Collecting jinja2<3.1,>=3.0 (from dataprep)\n",
            "  Downloading Jinja2-3.0.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting jsonpath-ng<2.0,>=1.5 (from dataprep)\n",
            "  Downloading jsonpath_ng-1.7.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting metaphone<0.7,>=0.6 (from dataprep)\n",
            "  Downloading Metaphone-0.6.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.7 in /usr/local/lib/python3.10/dist-packages (from dataprep) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.26.4)\n",
            "Collecting pandas<2.0,>=1.1 (from dataprep)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pydantic<2.0,>=1.6 (from dataprep)\n",
            "  Downloading pydantic-1.10.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.6/152.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydot<2.0.0,>=1.4.2 (from dataprep)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting python-crfsuite==0.9.8 (from dataprep)\n",
            "  Downloading python_crfsuite-0.9.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting python-stdnum<2.0,>=1.16 (from dataprep)\n",
            "  Downloading python_stdnum-1.20-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rapidfuzz<3.0.0,>=2.1.2 (from dataprep)\n",
            "  Downloading rapidfuzz-2.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting regex<2022.0.0,>=2021.8.3 (from dataprep)\n",
            "  Downloading regex-2021.11.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (39 kB)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.13.1)\n",
            "Collecting sqlalchemy==1.3.24 (from dataprep)\n",
            "  Downloading SQLAlchemy-1.3.24.tar.gz (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm<5.0,>=4.48 in /usr/local/lib/python3.10/dist-packages (from dataprep) (4.66.6)\n",
            "Collecting varname<0.9.0,>=0.8.1 (from dataprep)\n",
            "  Downloading varname-0.8.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: wordcloud<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.9.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.18.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (24.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (6.0.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (4.12.2)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (2024.10.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (1.4.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (8.5.0)\n",
            "INFO: pip is looking at multiple versions of dask[array,dataframe,delayed] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting dask[array,dataframe,delayed]>=2022.3.0 (from dataprep)\n",
            "  Downloading dask-2024.12.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.11.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.11.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.9.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.9.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.8.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.8.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of dask[array,dataframe,delayed] to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask-2024.8.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.7.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.7.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.6.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dask-expr<1.2,>=1.1 (from dask[array,dataframe,delayed]>=2022.3.0->dataprep)\n",
            "  Downloading dask_expr-1.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: Werkzeug>=2.3.7 in /usr/local/lib/python3.10/dist-packages (from flask<3,>=2->dataprep) (3.1.3)\n",
            "INFO: pip is looking at multiple versions of flask to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting flask<3,>=2 (from dataprep)\n",
            "  Downloading Flask-2.3.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading Flask-2.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading Flask-2.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading Flask-2.2.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask<3,>=2->dataprep) (2.2.0)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.10/dist-packages (from flask_cors<4.0.0,>=3.0.10->dataprep) (1.17.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (3.0.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.1,>=3.0->dataprep) (3.0.2)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.10/dist-packages (from jsonpath-ng<2.0,>=1.5->dataprep) (3.11)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.7->dataprep) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.1->dataprep) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.1->dataprep) (2024.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot<2.0.0,>=1.4.2->dataprep) (3.2.0)\n",
            "Collecting asttokens<3.0.0,>=2.0.0 (from varname<0.9.0,>=0.8.1->dataprep)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting executing<0.9.0,>=0.8.3 (from varname<0.9.0,>=0.8.1->dataprep)\n",
            "  Downloading executing-0.8.3-py2.py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting pure_eval<1.0.0 (from varname<0.9.0,>=0.8.1->dataprep)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from wordcloud<2.0,>=1.8->dataprep) (3.8.0)\n",
            "INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting dask-expr<1.2,>=1.1 (from dask[array,dataframe,delayed]>=2022.3.0->dataprep)\n",
            "  Downloading dask_expr-1.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading dask_expr-1.1.18-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading dask_expr-1.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: pip is still looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask_expr-1.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading dask_expr-1.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyarrow>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (17.0.0)\n",
            "  Downloading dask_expr-1.1.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting dask[array,dataframe,delayed]>=2022.3.0 (from dataprep)\n",
            "  Downloading dask-2024.6.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.6.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.5.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.5.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.5.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dask-expr<1.1,>=1.0 (from dask[array,dataframe,delayed]>=2022.3.0->dataprep)\n",
            "  Downloading dask_expr-1.0.14-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.13-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.12-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.10-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.9-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.6-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.5-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.4-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting dask[array,dataframe,delayed]>=2022.3.0 (from dataprep)\n",
            "  Downloading dask-2024.4.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.3.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "INFO: pip is still looking at multiple versions of flask to determine which version is compatible with other requirements. This could take a while.\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (3.21.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8.0,>=7.5->dataprep) (6.1.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (4.9.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (1.0.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (6.5.5)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0,>=3.6->dataprep) (3.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (1.4.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.8.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (7.16.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.10.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.5.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.22.3)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.2.2)\n",
            "Downloading dataprep-0.4.5-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bokeh-2.4.3-py3-none-any.whl (18.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/18.5 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask-2024.2.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask-2.2.5-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.6/133.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpath_ng-1.7.0-py3-none-any.whl (30 kB)\n",
            "Downloading pydantic-1.10.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading python_stdnum-1.20-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-2.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2021.11.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.0/764.0 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading varname-0.8.3-py3-none-any.whl (21 kB)\n",
            "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading executing-0.8.3-py2.py3-none-any.whl (16 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sqlalchemy, metaphone\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.24-cp310-cp310-linux_x86_64.whl size=1252697 sha256=f6de01a2e8fcb0b7d5648421dcfacb07a4fb81a23d2ee5be19c8c8398135a027\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/51/b3/3481e88d5a5ba95dd4aafedc9316774d941c4ba61cfb93add8\n",
            "  Building wheel for metaphone (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for metaphone: filename=Metaphone-0.6-py3-none-any.whl size=13901 sha256=c1c90f8b8062be4a0222e7d528bacfb7ac41f9baa1f1eb3e0e824a4d9d455839\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/dd/1d/6cdd346605db62bde1f60954155e9ce48f4681c243f265b704\n",
            "Successfully built sqlalchemy metaphone\n",
            "Installing collected packages: regex, python-stdnum, python-crfsuite, pure_eval, metaphone, executing, sqlalchemy, rapidfuzz, pydot, pydantic, jsonpath-ng, jinja2, jedi, asttokens, varname, pandas, flask, dask, bokeh, flask_cors, dataprep\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.9.11\n",
            "    Uninstalling regex-2024.9.11:\n",
            "      Successfully uninstalled regex-2024.9.11\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.3\n",
            "    Uninstalling pydot-3.0.3:\n",
            "      Successfully uninstalled pydot-3.0.3\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.3\n",
            "    Uninstalling pydantic-2.10.3:\n",
            "      Successfully uninstalled pydantic-2.10.3\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.4\n",
            "    Uninstalling Jinja2-3.1.4:\n",
            "      Successfully uninstalled Jinja2-3.1.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 3.0.3\n",
            "    Uninstalling Flask-3.0.3:\n",
            "      Successfully uninstalled Flask-3.0.3\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2024.10.0\n",
            "    Uninstalling dask-2024.10.0:\n",
            "      Successfully uninstalled dask-2024.10.0\n",
            "  Attempting uninstall: bokeh\n",
            "    Found existing installation: bokeh 3.6.2\n",
            "    Uninstalling bokeh-3.6.2:\n",
            "      Successfully uninstalled bokeh-3.6.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.10.19 which is incompatible.\n",
            "bigframes 1.27.0 requires sqlalchemy<3.0dev,>=1.4, but you have sqlalchemy 1.3.24 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "google-genai 0.1.0 requires pydantic<3.0.0dev,>=2.0.0, but you have pydantic 1.10.19 which is incompatible.\n",
            "holoviews 1.20.0 requires bokeh>=3.1, but you have bokeh 2.4.3 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.3.24 which is incompatible.\n",
            "langchain 0.3.11 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.19 which is incompatible.\n",
            "langchain 0.3.11 requires SQLAlchemy<3,>=1.4, but you have sqlalchemy 1.3.24 which is incompatible.\n",
            "langchain-core 0.3.24 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.19 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "panel 1.5.4 requires bokeh<3.7.0,>=3.5.0, but you have bokeh 2.4.3 which is incompatible.\n",
            "plotnine 0.14.3 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "sphinx 8.1.3 requires Jinja2>=3.1, but you have jinja2 3.0.3 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asttokens-2.4.1 bokeh-2.4.3 dask-2024.2.1 dataprep-0.4.5 executing-0.8.3 flask-2.2.5 flask_cors-3.0.10 jedi-0.19.2 jinja2-3.0.3 jsonpath-ng-1.7.0 metaphone-0.6 pandas-1.5.3 pure_eval-0.2.3 pydantic-1.10.19 pydot-1.4.2 python-crfsuite-0.9.8 python-stdnum-1.20 rapidfuzz-2.15.2 regex-2021.11.10 sqlalchemy-1.3.24 varname-0.8.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              },
              "id": "c37441b724b84b3daa3f606293e0751a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEg0AZiEKa5Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "a3853101-5595-457d-db60-1ca3f07ac39a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'bm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0f8810264db8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# keep only first city and first country\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'first_city'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'city_set_in'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'first_country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country_set_in'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"first_city\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"city\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"first_country\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"country\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bm' is not defined"
          ]
        }
      ],
      "source": [
        "# keep only first city and first country\n",
        "bm['first_city'] = bm['city_set_in'].str.lower().str.split(',').str[0]\n",
        "bm['first_country'] = bm['country_set_in'].str.lower().str.split(',').str[0]\n",
        "bm = bm.rename(columns={\"first_city\": \"city\", \"first_country\": \"country\"})\n",
        "\n",
        "# create country_iso column\n",
        "from dataprep.clean import clean_country\n",
        "bm_iso = clean_country(bm,\"country\",output_format=\"alpha-2\",fuzzy_dist=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bm_w_id = pd.merge(bm_iso, cities[['setting_id', 'city', 'country_iso']],\n",
        "                     left_on=['city_set_in', 'country_clean'],\n",
        "                     right_on=['city', 'country_iso'],\n",
        "                     how='left')\n",
        "\n",
        "cols_to_keep = ['id', 'title', 'description', 'image', 'preview_link', 'publisher',\n",
        "                'published_date', 'info_link', 'categories', 'ratings_count',\n",
        "                'film_name', 'classification', 'time_period_start',\n",
        "                'time_period_end', 'setting_id']\n",
        "\n",
        "bm_w_id = bm_w_id[cols_to_keep]\n",
        "bm_w_id = bm_w_id.drop_duplicates(subset='id', keep='first')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BkA4a5M5KwmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm_w_id['categories'] = bm_w_id['categories'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
        "bm_w_id['categories'] = bm_w_id['categories'].str.lower()\n"
      ],
      "metadata": {
        "id": "T8T0TbV7dM17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "print(bm_w_id.head())\n",
        "#print(bm_w_id['categories']).tolist()\n",
        "bm_w_id.to_csv('/content/drive/MyDrive/Colab Notebooks/5500_datasets/for_database_upload/amazon_books_final.csv', index=False, quoting=csv.QUOTE_MINIMAL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_NpFs6_m_EK",
        "outputId": "eb5a2b36-1944-4fca-dc6c-ac2a14210e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           id                                              title  \\\n",
            "0  1882931173                     Its Only Art If Its Well Hung!   \n",
            "1  0826414346                           Dr. Seuss: American Icon   \n",
            "2  0829814000              Wonderful Worship in Smaller Churches   \n",
            "3  0595344550                      Whispers of the Wicked Saints   \n",
            "4  0253338352  Nation Dance: Religion, Identity and Cultural ...   \n",
            "\n",
            "                                         description  \\\n",
            "0                                               None   \n",
            "1  Philip Nel takes a fascinating look into the k...   \n",
            "2  This resource includes twelve principles in un...   \n",
            "3  Julia Thomas finds her life spinning out of co...   \n",
            "4                                               None   \n",
            "\n",
            "                                               image  \\\n",
            "0  http://books.google.com/books/content?id=DykPA...   \n",
            "1  http://books.google.com/books/content?id=IjvHQ...   \n",
            "2  http://books.google.com/books/content?id=2tsDA...   \n",
            "3  http://books.google.com/books/content?id=aRSIg...   \n",
            "4                                               None   \n",
            "\n",
            "                                        preview_link  publisher  \\\n",
            "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...       None   \n",
            "1  http://books.google.nl/books?id=IjvHQsCn_pgC&p...  A&C Black   \n",
            "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...       None   \n",
            "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...  iUniverse   \n",
            "4  http://books.google.nl/books?id=399SPgAACAAJ&d...       None   \n",
            "\n",
            "  published_date                                          info_link  \\\n",
            "0           1996  http://books.google.nl/books?id=DykPAAAACAAJ&d...   \n",
            "1           2005  http://books.google.nl/books?id=IjvHQsCn_pgC&d...   \n",
            "2           2000  http://books.google.nl/books?id=2tsDAAAACAAJ&d...   \n",
            "3           2005  http://books.google.nl/books?id=aRSIgJlq6JwC&d...   \n",
            "4           2003  http://books.google.nl/books?id=399SPgAACAAJ&d...   \n",
            "\n",
            "                  categories  ratings_count film_name classification  \\\n",
            "0    comics & graphic novels            NaN      None           None   \n",
            "1  biography & autobiography            NaN      None           None   \n",
            "2                   religion            NaN      None           None   \n",
            "3                    fiction            NaN      None           None   \n",
            "4                       None            NaN      None           None   \n",
            "\n",
            "   time_period_start  time_period_end  setting_id  \n",
            "0                NaN              NaN         NaN  \n",
            "1                NaN              NaN         NaN  \n",
            "2                NaN              NaN         NaN  \n",
            "3                NaN              NaN         NaN  \n",
            "4                NaN              NaN         NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LfuQysjJjnAo",
        "outputId": "8397b2c5-4bd0-4ab2-b4c2-1c86b2697599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-150-51fe8e520211>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ratings_nona['review_helpfulness'] = ratings_nona.groupby(['user_id', 'book_id'])['review_helpfulness'].transform('mean')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All book IDs from ratings are present in bm_w_id.\n"
          ]
        }
      ],
      "source": [
        "### Clean ratings ###\n",
        "bm_ids = bm_w_id['id'].tolist()\n",
        "\n",
        "ratings_cleaned = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/cleaned_Books_rating.csv\")\n",
        "ratings_nona = ratings_cleaned.dropna(subset=['user_id']) # remove rows with NA values for user_id\n",
        "# for duplicated user + book id combos, replace helpfulness with average for book + user and drop duplicates\n",
        "ratings_nona['review_helpfulness'] = ratings_nona.groupby(['user_id', 'book_id'])['review_helpfulness'].transform('mean')\n",
        "ratings_nona = ratings_nona.drop_duplicates(subset=['user_id', 'book_id'])\n",
        "# drop rows with a book that isn't in Amazon books\n",
        "ratings_nona = ratings_nona[ratings_nona['book_id'].isin(bm_ids)]\n",
        "\n",
        "ratings_nona.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/for_database_upload/ratings_w_id_modified.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BX Dataset"
      ],
      "metadata": {
        "id": "4_1LV-9Fq3vb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smeVjUImCTXV"
      },
      "outputs": [],
      "source": [
        "bx_users = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/for_database_upload/bx_users_new_location.csv\")\n",
        "bx_users = bx_users.replace({pd.NA: None, pd.NaT: None, float('nan'): None})\n",
        "# check if location ID is in cities dataset\n",
        "rows_with_invalid_location = bx_users[~bx_users['location_id'].isin(cities['setting_id'])]\n",
        "bx_users.head()\n",
        "bx_users.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/for_database_upload/bx_users_new_location_modified.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install dataprep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "24VpKei5uFv2",
        "outputId": "76b24618-fbb0-447c-98b9-6514805bae00",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dataprep\n",
            "  Downloading dataprep-0.4.5-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.6 in /usr/local/lib/python3.10/dist-packages (from dataprep) (3.11.2)\n",
            "Collecting bokeh<3,>=2 (from dataprep)\n",
            "  Downloading bokeh-2.4.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: dask>=2022.3.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (2024.10.0)\n",
            "Collecting flask<3,>=2 (from dataprep)\n",
            "  Downloading flask-2.3.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting flask_cors<4.0.0,>=3.0.10 (from dataprep)\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: ipywidgets<8.0,>=7.5 in /usr/local/lib/python3.10/dist-packages (from dataprep) (7.7.1)\n",
            "Collecting jinja2<3.1,>=3.0 (from dataprep)\n",
            "  Downloading Jinja2-3.0.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting jsonpath-ng<2.0,>=1.5 (from dataprep)\n",
            "  Downloading jsonpath_ng-1.7.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting metaphone<0.7,>=0.6 (from dataprep)\n",
            "  Downloading Metaphone-0.6.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.7 in /usr/local/lib/python3.10/dist-packages (from dataprep) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.26.4)\n",
            "Collecting pandas<2.0,>=1.1 (from dataprep)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pydantic<2.0,>=1.6 (from dataprep)\n",
            "  Downloading pydantic-1.10.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.6/152.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydot<2.0.0,>=1.4.2 (from dataprep)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting python-crfsuite==0.9.8 (from dataprep)\n",
            "  Downloading python_crfsuite-0.9.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting python-stdnum<2.0,>=1.16 (from dataprep)\n",
            "  Downloading python_stdnum-1.20-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rapidfuzz<3.0.0,>=2.1.2 (from dataprep)\n",
            "  Downloading rapidfuzz-2.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting regex<2022.0.0,>=2021.8.3 (from dataprep)\n",
            "  Downloading regex-2021.11.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (39 kB)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.13.1)\n",
            "Collecting sqlalchemy==1.3.24 (from dataprep)\n",
            "  Downloading SQLAlchemy-1.3.24.tar.gz (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm<5.0,>=4.48 in /usr/local/lib/python3.10/dist-packages (from dataprep) (4.66.6)\n",
            "Collecting varname<0.9.0,>=0.8.1 (from dataprep)\n",
            "  Downloading varname-0.8.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: wordcloud<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.9.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (4.0.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (24.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (6.0.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (4.12.2)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (2024.10.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (1.4.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (8.5.0)\n",
            "INFO: pip is looking at multiple versions of dask[array,dataframe,delayed] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting dask[array,dataframe,delayed]>=2022.3.0 (from dataprep)\n",
            "  Downloading dask-2024.11.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.11.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.9.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.9.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.8.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.8.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.8.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of dask[array,dataframe,delayed] to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask-2024.7.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.7.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.6.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dask-expr<1.2,>=1.1 (from dask[array,dataframe,delayed]>=2022.3.0->dataprep)\n",
            "  Downloading dask_expr-1.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: Werkzeug>=2.3.7 in /usr/local/lib/python3.10/dist-packages (from flask<3,>=2->dataprep) (3.1.3)\n",
            "INFO: pip is looking at multiple versions of flask to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting flask<3,>=2 (from dataprep)\n",
            "  Downloading Flask-2.3.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading Flask-2.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading Flask-2.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading Flask-2.2.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask<3,>=2->dataprep) (2.2.0)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.10/dist-packages (from flask_cors<4.0.0,>=3.0.10->dataprep) (1.16.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (3.0.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.1,>=3.0->dataprep) (3.0.2)\n",
            "Collecting ply (from jsonpath-ng<2.0,>=1.5->dataprep)\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.7->dataprep) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.1->dataprep) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.1->dataprep) (2024.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot<2.0.0,>=1.4.2->dataprep) (3.2.0)\n",
            "Collecting asttokens<3.0.0,>=2.0.0 (from varname<0.9.0,>=0.8.1->dataprep)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting executing<0.9.0,>=0.8.3 (from varname<0.9.0,>=0.8.1->dataprep)\n",
            "  Downloading executing-0.8.3-py2.py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting pure_eval<1.0.0 (from varname<0.9.0,>=0.8.1->dataprep)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from wordcloud<2.0,>=1.8->dataprep) (3.8.0)\n",
            "INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting dask-expr<1.2,>=1.1 (from dask[array,dataframe,delayed]>=2022.3.0->dataprep)\n",
            "  Downloading dask_expr-1.1.18-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading dask_expr-1.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: pip is still looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask_expr-1.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyarrow>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (17.0.0)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading dask_expr-1.1.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting dask[array,dataframe,delayed]>=2022.3.0 (from dataprep)\n",
            "  Downloading dask-2024.6.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.6.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.5.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.5.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.5.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dask-expr<1.1,>=1.0 (from dask[array,dataframe,delayed]>=2022.3.0->dataprep)\n",
            "  Downloading dask_expr-1.0.14-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.13-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.12-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.10-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.9-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.6-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.5-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.4-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading dask_expr-1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting dask[array,dataframe,delayed]>=2022.3.0 (from dataprep)\n",
            "  Downloading dask-2024.4.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.3.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "INFO: pip is still looking at multiple versions of flask to determine which version is compatible with other requirements. This could take a while.\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (3.21.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8.0,>=7.5->dataprep) (6.1.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (4.9.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask>=2022.3.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (1.0.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (6.5.5)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0,>=3.6->dataprep) (3.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (1.4.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.8.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (7.16.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.5.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.21.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.2.2)\n",
            "Downloading dataprep-0.4.5-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bokeh-2.4.3-py3-none-any.whl (18.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/18.5 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask-2024.2.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask-2.2.5-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.6/133.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpath_ng-1.7.0-py3-none-any.whl (30 kB)\n",
            "Downloading pydantic-1.10.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading python_stdnum-1.20-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-2.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2021.11.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.0/764.0 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading varname-0.8.3-py3-none-any.whl (21 kB)\n",
            "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading executing-0.8.3-py2.py3-none-any.whl (16 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sqlalchemy, metaphone\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.24-cp310-cp310-linux_x86_64.whl size=1252687 sha256=7da003e4b9fb7fcecef47a6b9f57cef11769c587bf25ac41609b61a1b20c4dd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/51/b3/3481e88d5a5ba95dd4aafedc9316774d941c4ba61cfb93add8\n",
            "  Building wheel for metaphone (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for metaphone: filename=Metaphone-0.6-py3-none-any.whl size=13901 sha256=0adc12527adb3e7d9d70c3371287bfed1269b6ad6425f7413c214ce0216aff8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/dd/1d/6cdd346605db62bde1f60954155e9ce48f4681c243f265b704\n",
            "Successfully built sqlalchemy metaphone\n",
            "Installing collected packages: regex, python-stdnum, python-crfsuite, pure_eval, ply, metaphone, executing, sqlalchemy, rapidfuzz, pydot, pydantic, jsonpath-ng, jinja2, jedi, asttokens, varname, pandas, flask, dask, bokeh, flask_cors, dataprep\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.9.11\n",
            "    Uninstalling regex-2024.9.11:\n",
            "      Successfully uninstalled regex-2024.9.11\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.2\n",
            "    Uninstalling pydot-3.0.2:\n",
            "      Successfully uninstalled pydot-3.0.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.9.2\n",
            "    Uninstalling pydantic-2.9.2:\n",
            "      Successfully uninstalled pydantic-2.9.2\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.4\n",
            "    Uninstalling Jinja2-3.1.4:\n",
            "      Successfully uninstalled Jinja2-3.1.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 3.0.3\n",
            "    Uninstalling Flask-3.0.3:\n",
            "      Successfully uninstalled Flask-3.0.3\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2024.10.0\n",
            "    Uninstalling dask-2024.10.0:\n",
            "      Successfully uninstalled dask-2024.10.0\n",
            "  Attempting uninstall: bokeh\n",
            "    Found existing installation: bokeh 3.6.1\n",
            "    Uninstalling bokeh-3.6.1:\n",
            "      Successfully uninstalled bokeh-3.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.10.19 which is incompatible.\n",
            "bigframes 1.27.0 requires sqlalchemy<3.0dev,>=1.4, but you have sqlalchemy 1.3.24 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "holoviews 1.20.0 requires bokeh>=3.1, but you have bokeh 2.4.3 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.3.24 which is incompatible.\n",
            "langchain 0.3.7 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.19 which is incompatible.\n",
            "langchain 0.3.7 requires SQLAlchemy<3,>=1.4, but you have sqlalchemy 1.3.24 which is incompatible.\n",
            "langchain-core 0.3.19 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.19 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "panel 1.5.4 requires bokeh<3.7.0,>=3.5.0, but you have bokeh 2.4.3 which is incompatible.\n",
            "plotnine 0.14.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "sphinx 8.1.3 requires Jinja2>=3.1, but you have jinja2 3.0.3 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asttokens-2.4.1 bokeh-2.4.3 dask-2024.2.1 dataprep-0.4.5 executing-0.8.3 flask-2.2.5 flask_cors-3.0.10 jedi-0.19.2 jinja2-3.0.3 jsonpath-ng-1.7.0 metaphone-0.6 pandas-1.5.3 ply-3.11 pure_eval-0.2.3 pydantic-1.10.19 pydot-1.4.2 python-crfsuite-0.9.8 python-stdnum-1.20 rapidfuzz-2.15.2 regex-2021.11.10 sqlalchemy-1.3.24 varname-0.8.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              },
              "id": "43f209e4fb16445a83517fd0d10a1885"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj2Gy18KcOm0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "# add enrichment data to bx books\n",
        "bx_books = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/bx_books.csv\")\n",
        "bx_enrichment = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/enrichments/bx_enrichment_ratingsGT2_numratings>2.csv\")\n",
        "bx_books = bx_books.drop(columns=['film_name', 'classification', 'time_period_start', 'time_period_end'])\n",
        "enrichment_noduplicates = bx_enrichment.drop_duplicates(subset=['name', 'authors'], keep='first')\n",
        "bx_enriched = bx_books.merge(enrichment_noduplicates,\n",
        "                             left_on=['title', 'author'],\n",
        "                             right_on=['name', 'authors'],\n",
        "                             how='left').drop(columns=['name', 'authors'])\n",
        "\n",
        "def extract_periods(value):\n",
        "    if isinstance(value, str):\n",
        "        # Handle \"various time periods\" (or similar unrecognized text)\n",
        "        if 'various time periods' in value.lower():\n",
        "            return None, None\n",
        "\n",
        "        # Handle \"Contemporary\" (let's assume contemporary is 2000 to current year)\n",
        "        if 'contemporary' in value.lower():\n",
        "            current_year = datetime.now().year\n",
        "            return 2000, current_year  # Assuming \"Contemporary\" means 2000-present\n",
        "\n",
        "        # Handle \"c. X BC - c. Y BC\" by processing the 'c.' and BCE years\n",
        "        if 'c.' in value.lower() and 'BC' in value.upper():\n",
        "            value = value.replace('c.', '').strip()  # Remove 'c.'\n",
        "            parts = re.split(r'\\s*-\\s*', value)\n",
        "            start, end = None, None\n",
        "\n",
        "            if len(parts) == 2:  # Ensure we have a range\n",
        "                # Handle the start date\n",
        "                start_match = re.search(r'(\\d+)\\s*BC', parts[0], re.IGNORECASE)\n",
        "                if start_match:\n",
        "                    start = -int(start_match.group(1))  # BCE years are negative\n",
        "\n",
        "                # Handle the end date\n",
        "                end_match = re.search(r'(\\d+)\\s*BC', parts[1], re.IGNORECASE)\n",
        "                if end_match:\n",
        "                    end = -int(end_match.group(1))  # BCE years are negative\n",
        "\n",
        "            return start, end\n",
        "\n",
        "        # Handle \"about X - Y\" by removing \"about\" and processing the numbers\n",
        "        if 'about' in value.lower():\n",
        "            value = value.lower().replace('about', '').strip()\n",
        "            parts = re.split(r'\\s*-\\s*', value)\n",
        "            if len(parts) == 2:\n",
        "                start = int(parts[0].replace(',', ''))  # Remove commas and convert to int\n",
        "                end = int(parts[1].replace(',', ''))    # Same for the second number\n",
        "                return start, end\n",
        "\n",
        "        # Handle '19th century'\n",
        "        elif re.search(r'\\d{1,2}(st|nd|rd|th) century', value, re.IGNORECASE):\n",
        "            match = re.search(r'(\\d{1,2})', value)\n",
        "            if match:\n",
        "                century = int(match.group(1))\n",
        "                start = (century - 1) * 100\n",
        "                end = start + 99\n",
        "                return start, end\n",
        "\n",
        "        # Handle a range like '1930-1940'\n",
        "        elif ' - ' in value:\n",
        "            parts = value.split(' - ')\n",
        "            if len(parts) == 2 and all(part.isdigit() for part in parts):\n",
        "                start = int(parts[0])\n",
        "                end = int(parts[1])\n",
        "                return min(start, end), max(start, end)  # Ensure we return a valid range\n",
        "\n",
        "        # Handle centuries like '19th century'\n",
        "        elif re.search(r'\\d{1,2}(st|nd|rd|th) century', value, re.IGNORECASE):\n",
        "            match = re.search(r'(\\d{1,2})', value)\n",
        "            if match:\n",
        "                century = int(match.group(1))\n",
        "                start = (century - 1) * 100\n",
        "                end = start + 99\n",
        "                return start, end\n",
        "\n",
        "        # Handle ranges with BCE/CE (e.g., 'c. 1200 BCE - 70 CE')\n",
        "        if re.search(r'BCE|CE', value, re.IGNORECASE):\n",
        "            value = value.replace(\"c.\", \"\").strip()  # Remove 'c.' if present\n",
        "            parts = re.split(r'\\s*-\\s*', value)\n",
        "            start, end = None, None\n",
        "\n",
        "            if len(parts) == 2:  # Ensure we have a range\n",
        "                # Handle the start date\n",
        "                start_match = re.search(r'(\\d+)\\s*(BCE|CE)', parts[0], re.IGNORECASE)\n",
        "                if start_match:\n",
        "                    start = int(start_match.group(1))\n",
        "                    if start_match.group(2).upper() == \"BCE\":\n",
        "                        start = -start  # BCE years are negative\n",
        "\n",
        "                # Handle the end date\n",
        "                end_match = re.search(r'(\\d+)\\s*(BCE|CE)', parts[1], re.IGNORECASE)\n",
        "                if end_match:\n",
        "                    end = int(end_match.group(1))\n",
        "                    if end_match.group(2).upper() == \"BCE\":\n",
        "                        end = -end  # BCE years are negative\n",
        "\n",
        "            return start, end\n",
        "\n",
        "        # Handle single years like '1899' or '1200 BCE'\n",
        "        elif re.search(r'\\d+\\s*(BCE|CE)', value, re.IGNORECASE):\n",
        "            match = re.search(r'(\\d+)\\s*(BCE|CE)', value, re.IGNORECASE)\n",
        "            year = int(match.group(1))\n",
        "            if match.group(2).upper() == \"BCE\":\n",
        "                year = -year  # BCE years are negative\n",
        "            return year, year\n",
        "\n",
        "        elif value.isdigit():  # Single numeric year\n",
        "            year = int(value)\n",
        "            return year, year\n",
        "\n",
        "        # If the value is unrecognized text, print it and return None\n",
        "        return None, None\n",
        "\n",
        "    # If the value is None or empty string, return None\n",
        "    return None, None\n",
        "\n",
        "bx_enriched[['time_period_start', 'time_period_end']] = bx_enriched['period_set_in'].apply(extract_periods).apply(pd.Series)\n",
        "bx_enriched = bx_enriched.drop(columns=['period_set_in'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specific case handling for \"New York, Toronto\"\n",
        "mask = bx_enriched[\"city_set_in\"] == \"New York, Toronto\"\n",
        "bx_enriched.loc[mask, \"city_set_in\"] = \"New York\"\n",
        "bx_enriched.loc[mask, \"country_set_in\"] = \"United States\""
      ],
      "metadata": {
        "id": "tjidPk1X1n93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixing city_set_in and country_set_in to keep only the first value if multiple\n",
        "bx_enriched[\"city_set_in\"] = bx_enriched[\"city_set_in\"].str.split(\",\").str[0].str.strip()\n",
        "bx_enriched[\"country_set_in\"] = bx_enriched[\"country_set_in\"].str.split(\",\").str[0].str.strip()"
      ],
      "metadata": {
        "id": "3hpyBDy20h3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataprep.clean import clean_country\n",
        "bx_enriched = clean_country(bx_enriched,\"country_set_in\",output_format=\"alpha-2\",fuzzy_dist=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yugHqvNGyPi8",
        "outputId": "b9c2d31c-f13b-4bae-bfdd-babf765a3173",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py:7365: FutureWarning: Meta is not valid, `map_partitions` and `map_overlap` expects output to be a pandas object. Try passing a pandas object as meta or a dict or tuple representing the (name, dtype) of the columns. In the future the meta you passed will not work.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Country Cleaning Report:\n",
            "\t43912 values cleaned (16.18%)\n",
            "\t2 values unable to be parsed (0.0%), set to NaN\n",
            "Result contains 43912 (16.18%) values in the correct format and 227467 null values (83.82%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merge with cities to get location set in\n",
        "bx_enriched_merged = pd.merge(bx_enriched, cities[['setting_id', 'city', 'country_iso']],\n",
        "                     left_on=['city_set_in', 'country_set_in_clean'],\n",
        "                     right_on=['city', 'country_iso'],\n",
        "                     how='left')"
      ],
      "metadata": {
        "id": "9tGGnLfpx5C_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop set_in_location column\n",
        "bx_enriched_merged = bx_enriched_merged.drop(columns=['set_in_location'])"
      ],
      "metadata": {
        "id": "TrNusemuFH_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename setting_id to set_in_location\n",
        "bx_enriched_merged = bx_enriched_merged.rename(columns={\"setting_id\": \"set_in_location\"})"
      ],
      "metadata": {
        "id": "cP2ybII-FoIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_keep = ['isbn', 'title', 'author', 'year_published', 'publisher', 'image_url_s',\n",
        "           'image_url_m', 'image_url_l', 'summary', 'language', 'category',\n",
        "           'film_name', 'classification', 'set_in_location', 'time_period_start',\n",
        "           'time_period_end']\n",
        "bx_enriched_merged = bx_enriched_merged[to_keep]\n",
        "bx_enriched_merged = bx_enriched_merged.drop_duplicates(subset=['isbn'], keep='first')"
      ],
      "metadata": {
        "id": "dmjucVOzx0Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bx_enriched = bx_books\n",
        "bx_reviews = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/bx_reviews.csv\")\n",
        "bx_users_ids = bx_users['id'].tolist()\n",
        "bx_books_isbns = bx_enriched_merged['isbn'].tolist()\n",
        "bx_reviews = bx_reviews[bx_reviews['user_id'].isin(bx_users_ids)]\n",
        "bx_reviews = bx_reviews[bx_reviews['isbn'].isin(bx_books_isbns)]"
      ],
      "metadata": {
        "id": "LbU-31afSex7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check foreign key constraints"
      ],
      "metadata": {
        "id": "Ld3VJRk1ziL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bx_books\n",
        "rows_with_invalid_location = bx_enriched_merged[~bx_enriched_merged['set_in_location'].isin(cities['setting_id'])]\n",
        "rows_with_invalid_location['set_in_location'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdNfPgjIzTZS",
        "outputId": "5dac0b6a-3bd9-4ae8-f6b6-66ca0af96aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan])"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bx_users\n",
        "rows_with_invalid_location = bx_users[~bx_users['location_id'].isin(cities['setting_id'])]\n",
        "print(rows_with_invalid_location['location_id'].unique())\n",
        "\n",
        "#bx_ratings\n",
        "rows_with_invalid_book = bx_reviews[~bx_reviews['isbn'].isin(bx_enriched_merged['isbn'])]\n",
        "print(rows_with_invalid_book['isbn'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gry_9gPzpKC",
        "outputId": "7b28bd67-cb76-4359-da11-93092a620f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Replace NaN values with None values"
      ],
      "metadata": {
        "id": "-B0gNQG40Rqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bx_reviews = bx_reviews.replace({pd.NA: None, pd.NaT: None, float('nan'): None})\n",
        "bx_enriched_merged = bx_enriched_merged.replace({pd.NA: None, pd.NaT: None, float('nan'): None})\n",
        "bx_users = bx_users.replace({pd.NA: None, pd.NaT: None, float('nan'): None})"
      ],
      "metadata": {
        "id": "_1JCDix30T0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save dataframes"
      ],
      "metadata": {
        "id": "tr_prViKUbFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bx_enriched_merged.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/for_database_upload/bx_books_final_final.csv\", index=False)\n",
        "bx_reviews.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/for_database_upload/bx_reviews_final.csv\", index=False)\n",
        "bx_users.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5500_datasets/for_database_upload/bx_users_final.csv\", index=False)"
      ],
      "metadata": {
        "id": "GPmAzWZYDVlr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}